# Project Overview: Banking Customer Churn Prediction

### âš™ï¸ Code: [Churn_Prediction_Model.ipynb](https://github.com/lekhakasinadhuni07/Churn-Prediction-Model/blob/main/Banking_Churn_Prediction_model.ipynb)


### ğŸ¯ Goals:
- Predict whether a bank customer is likely to churn based on historical data.
- Analyze key factors influencing customer retention.
- Build an accurate machine learning model to classify customers as "churn" or "retain.


### ğŸ“– Description:
This project focuses on customer churn prediction in the banking industry using machine learning algorithms. The dataset includes demographic, financial, and transaction-related features to identify patterns among customers likely to leave.

âœ” **Data Cleaning & Preprocessing** (Handling missing values, encoding categorical variables)

âœ” **Exploratory Data Analysis** (Visualizing correlations and trends)

âœ” **Feature Engineering** (Transforming data for better predictions)

âœ” **Model Training & Evaluation** (Random Forest Classifier)

âœ” **Performance Metrics** (Confusion Matrix, Accuracy Score, Classification Report)


## ğŸ“Š Model Evaluation Summary

Tested the following machine learning models to predict customer churn, evaluating them using accuracy, precision, recall, and F1-score.

| Model                        | Accuracy | Precision (Class 1) | Recall (Class 1) | F1-Score (Class 1) |
|------------------------------|----------|----------------------|------------------|-------------------|
| **Random Forest**            | 86.65%   | 76%                  | 46%              | 58%               |
| **Logistic Regression**      | 81.1%    | 55%                  | 20%              | 29%               |
| **Support Vector Machine**   | 79.7%    | 48%                  | 32%              | 38%               |
| **K-Nearest Neighbors (KNN)**| 83%      | 61%                  | 37%              | 46%               |
| **Gradient Boosting**        | 86.75%   | 75%                  | 49%              | 59%               |

---

## ğŸ“Œ Model Insights

### **1ï¸âƒ£ Random Forest Classifier**
- **Accuracy:** 86.65%
- **Strengths:** High accuracy and good precision.
- **Weaknesses:** Recall for churned customers (46%) is relatively low, meaning the model misses a significant number of actual churn cases.

### **2ï¸âƒ£ Logistic Regression**
- **Accuracy:** 81.1%
- **Strengths:** Simple and interpretable model.
- **Weaknesses:** Poor recall (20%) for churned customers, making it unreliable for identifying at-risk customers.

### **3ï¸âƒ£ Support Vector Machine (SVM)**
- **Accuracy:** 79.7%
- **Strengths:** Effective in complex decision boundaries.
- **Weaknesses:** Low recall (32%) and F1-score (38%) for churned customers, making it less reliable for churn prediction.

### **4ï¸âƒ£ K-Nearest Neighbors (KNN)**
- **Accuracy:** 83%
- **Strengths:** Higher precision (61%) than SVM and Logistic Regression.
- **Weaknesses:** Struggles with recall (37%) and may be sensitive to data size and distribution.

### **5ï¸âƒ£ Gradient Boosting Classifier**
- **Accuracy:** **86.75% (Best Performance)**
- **Strengths:** Highest accuracy and a good balance of precision (75%) and recall (49%).
- **Weaknesses:** Computationally expensive compared to simpler models.

---

## âœ… **Conclusion & Recommendation**

Based on the evaluation, the **Gradient Boosting Classifier** emerges as the best model with the highest accuracy (**86.75%**) and a balanced trade-off between precision and recall.

### ğŸš€ **Next Steps:**
- **Feature Engineering:** Identify additional customer behavior indicators.
- **Data Balancing Techniques:** Improve recall by handling class imbalance.
- **Hyperparameter Tuning:** Optimize the model for better performance.

Implementing the Gradient Boosting model can enhance the bankâ€™s ability to **identify and retain high-risk customers**, leading to improved customer satisfaction and reduced churn rates.

---

## ğŸ›  Skills Demonstrated:
âœ… **Machine Learning** (Supervised Learning, Classification)

âœ… **Data Preprocessing & Feature Engineering**

âœ… **Data Visualization** (Matplotlib, Seaborn)

âœ… **Model Evaluation** (Confusion Matrix, Precision-Recall, Accuracy)

âœ… **SQL-like Data Handling** (Pandas, NumPy)

## ğŸ–¥ Technologies & Tools Used:
ğŸ”¹ **Python** (Pandas, NumPy, Scikit-Learn, Matplotlib, Seaborn)

ğŸ”¹ **Machine Learning** (Random Forest Classifier)

ğŸ”¹ **Feature Encoding** (Label Encoding, One-Hot Encoding)

ğŸ”¹ **Data Handling** (Pandas for CSV processing, handling missing values)

---

**ğŸ“Œ Note:** This report is based on a dataset of 2,000 samples. Further testing and model fine-tuning may be needed before deployment.
